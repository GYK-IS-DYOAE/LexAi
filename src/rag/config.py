"""
config.py
---------
TÃ¼m servis ve model ayarlarÄ± bu dosyada toplanmÄ±ÅŸtÄ±r.
Retrieval (arama) ve LLM (cevap Ã¼retimi) bileÅŸenleri iÃ§in merkezi yapÄ± saÄŸlar.
"""

# ======================================
# ğŸ” OpenSearch â€“ Anahtar kelime arama
# ======================================
OS_HOST = "localhost"
OS_PORT = 9200
OS_USER = None      # GÃ¼venlik kapalÄ±ysa kullanÄ±cÄ±/ÅŸifre boÅŸ kalÄ±r
OS_PASS = None
OS_INDEX = "lexai_cases"

# ======================================
# ğŸ§  Qdrant â€“ VektÃ¶r (dense) arama
# ======================================
QDRANT_HOST = "localhost"
QDRANT_PORT = 6333
QDRANT_COLLECTION = "lexai_cases"

# ======================================
# âœ¨ Embedding Model (Retrieval iÃ§in)
# ======================================
EMBED_MODEL_NAME = "BAAI/bge-m3"   # Sentence embedding modeli

# ======================================
# ğŸ§¾ Prompt & Cevap AyarlarÄ±
# ======================================
MAX_PASSAGE_CHARS = 1200           # Her pasajdan LLM'e en fazla kaÃ§ karakter verilecek
MAX_TOTAL_PASSAGES = 8             # LLM'e en fazla kaÃ§ pasaj gÃ¶nderilecek

# ======================================
# âš–ï¸ Hibrit Arama Parametreleri
# ======================================
TOP_K_OS = 50                      # OpenSearchâ€™ten kaÃ§ sonuÃ§ alÄ±nsÄ±n
TOP_K_QDRANT = 50                  # Qdrantâ€™tan kaÃ§ sonuÃ§ alÄ±nsÄ±n
MMR_LAMBDA = 0.5                   # MMR denge katsayÄ±sÄ± (0=Ã§eÅŸitlilik, 1=benzerlik)
DEFAULT_TOPN = 8                   # KullanÄ±cÄ±ya gÃ¶sterilecek sonuÃ§ sayÄ±sÄ±

# ======================================
# ğŸ§  LLM AyarlarÄ± (Cevap Ã¼retimi iÃ§in)
# ======================================
LLM_BACKEND = "ollama"             # "ollama", "openai", "vllm" vb. olabilir
LLM_MODEL_NAME = "qwen:7b"         # Ollama'da yÃ¼klÃ¼ model adÄ±
LLM_BASE_URL = "http://localhost:11434"  # LLM API endpoint
LLM_TIMEOUT = 60                   # Ä°stek zaman aÅŸÄ±mÄ± (saniye)
